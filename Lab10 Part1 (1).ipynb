{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_6914e300bea88191a0f4abe12b8c6dc7\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-QEMuudr6WRbx7QC4F6Y7Wq\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-QEMuudr6WRbx7QC4F6Y7Wq\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest updates in 2023, generative AI continues to make significant strides in various areas. Key developments include:\n",
       "\n",
       "1. **Advanced Language Models**: Models like GPT-4 have become more sophisticated, with improved understanding, context handling, and creativity in generating human-like text.\n",
       "\n",
       "2. **Multimodal Models**: Systems like DALL-E 3 and CLIP are pushing boundaries by integrating text and image generation, allowing for more interactive and versatile AI applications.\n",
       "\n",
       "3. **Real-Time Applications**: AI-generated content is being used in real-time applications, such as virtual assistants, customer service bots, and real-time translation services.\n",
       "\n",
       "4. **Ethical and Safe AI**: There is a growing focus on developing ethical AI frameworks to ensure generative AI is used responsibly, addressing concerns such as bias, misinformation, and privacy.\n",
       "\n",
       "5. **Creative Industries**: AI is becoming a tool for artists, musicians, and writers, aiding in creating artworks, composing music, and writing stories, enhancing creativity with computational power.\n",
       "\n",
       "6. **Customization and Personalization**: Generative AI is being used to tailor content and experiences to individual preferences, from personalized learning environments to customized marketing strategies.\n",
       "\n",
       "7. **Improved Training Techniques**: Researchers are working on more efficient training methods, reducing the computational resources needed and improving the scalability of models.\n",
       "\n",
       "These developments highlight the rapid evolution and expanding capabilities of generative AI, influencing a wide range of industries and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include:\n",
       "\n",
       "1. **Agentic Workflows**: Amazon Web Services is exploring the future of AI with a focus on agentic workflows, which are being showcased alongside startups like NeuralSeek and Tarpit AI.\n",
       "\n",
       "2. **AI in Supply Chain**: Atos has developed an AI-powered Supply Chain Disruption Analysis using generative AI, SAP BTP, and AWS Bedrock to assess risk and boost resilience.\n",
       "\n",
       "3. **AI in Content Creation**: Generative AI is being used to create cinematic videos from prompts, incorporating audio and physics, which is a game changer for creators.\n",
       "\n",
       "4. **Market Growth**: The global generative AI market is expected to reach $1.18 billion this year, highlighting its rapid growth and adoption across various sectors.\n",
       "\n",
       "5. **Enterprise Applications**: IBM's Watsonx is bringing generative AI to enterprises, allowing teams to build custom large language models for enhanced customer engagement and streamlined processes.\n",
       "\n",
       "These developments indicate a broadening application of generative AI across industries, from creative content to enterprise solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a detailed overview of the **latest developments in generative AI** as of November 12, 2025, based on recent news and industry announcements. For clarity, this response is structured into key focus areas, each supported with up‚Äëto‚Äëdate evidence.\n",
       "\n",
       "---\n",
       "\n",
       "##  Foundational Models & Multimodal Advances\n",
       "\n",
       "- **OpenAI‚Äôs GPT‚Äë5**  \n",
       "  Released on **August 7, 2025**, GPT‚Äë5 is the fifth-generation multimodal large language model. It combines reasoning and non‚Äëreasoning capabilities and is integrated into ChatGPT, Microsoft Copilot, and accessible via OpenAI‚Äôs API, delivering state-of-the-art benchmark performance ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).\n",
       "\n",
       "- **Google‚Äôs Gemini Enhancements and ‚ÄúNano Banana‚Äù**  \n",
       "  - Throughout 2025, Google rolled out several advanced variants in its Gemini model family, culminating in Gemini 2.5 Pro (state-of-the-art reasoning and coding capabilities) and Gemini 2.5 Flash (optimized for speed), both becoming generally available in **June 2025** ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai)).  \n",
       "  - In **August 2025**, Google introduced ‚ÄúNano Banana‚Äù (Gemini‚ÄØ2.5 Flash Image), a viral image editing model notable for photorealistic 3D-style ‚Äúfigurine‚Äù effects, subject consistency, multi-image fusion, and invisible SynthID watermarking ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "- **Runway Gen‚Äë4 (Text-to‚ÄëVideo AI)**  \n",
       "  Launched on **March 31, 2025**, Runway Gen-4 generates 5‚Äì10 second video clips from text prompts and reference images, supporting various resolutions (e.g., 720p) and delivering consistent characters within individual clips‚Äîa milestone in AI video generation ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai)).\n",
       "\n",
       "- **OpenAI Sora 2**  \n",
       "  On **September 30, 2025**, OpenAI released Sora 2, a model capable of generating synchronized video with audio, enabling multi-shot consistency. This launch was accompanied by the Sora app, which functions as a social platform for AI-generated short clips‚Äîsignaling a shift toward socialized content creation, albeit with raised concerns about IP and content moderation ([champaignmagazine.com](https://champaignmagazine.com/2025/10/05/ai-by-ai-weekly-top-5-september-29-october-5-2025/?utm_source=openai)).\n",
       "\n",
       "- **Other Notable Model Launches**  \n",
       "  - **Anthropic Claude Haiku 4.5** ‚Äî A compact model launched in **October 2025** delivering flagship-level reasoning and coding abilities at 4‚Äì5√ó the speed and ~1/3 the cost of larger models. It supports a 200K-token context window and includes agentic capabilities ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai)).  \n",
       "  - **Gemini Diffusion** ‚Äî A novel experimental model by DeepMind applying diffusion techniques to text generation, enabling simultaneous text production and in-process error correction, achieving speeds up to 1,479 tokens per second ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai)).  \n",
       "  - **Alibaba Qwen3 Series** ‚Äî Released in **April 2025**, this open-source model family (under Apache 2.0) includes dense models up to 32B parameters and MoE variants, delivering robust performance across coding, math, and instruction tasks in both ‚Äúthinking‚Äù and ‚Äúnon‚Äëthinking‚Äù modes ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Specialized Applications & Research Innovations\n",
       "\n",
       "- **Material Science with Generative AI**  \n",
       "  - **SCIGEN**: MIT researchers introduced a tool that guides generative AI to design materials following structural ‚Äúdesign rules,‚Äù accelerating the discovery of novel quantum materials with desired geometric properties ([news.mit.edu](https://news.mit.edu/2025/new-tool-makes-generative-ai-models-likely-create-breakthrough-materials-0922?utm_source=openai)).  \n",
       "  - **Energy Storage**: NJIT scientists applied AI to explore sustainable alternatives to lithium-ion batteries, advancing material innovation in energy domains ([news.njit.edu](https://news.njit.edu/ai-breakthrough-njit-unlocks-new-materials-replace-lithium-ion-batteries?utm_source=openai)).\n",
       "\n",
       "- **Personalized Object Localization**  \n",
       "  MIT developed a training method enabling vision-language generative AI to recognize and localize personalized objects (e.g., a pet named ‚ÄúSnoofkin‚Äù) across new scenes‚Äîenhancing customization in image generation tasks ([news.mit.edu](https://news.mit.edu/2025/method-teaches-generative-ai-models-locate-personalized-objects-1016?utm_source=openai)).\n",
       "\n",
       "- **Optical Generative Models**  \n",
       "  UCLA researchers pioneered optical generative models that leverage light physics rather than electronic computation to create images, pointing toward more sustainable and energy-efficient AI methods ([phys.org](https://phys.org/news/2025-08-optical-generative-ushering-era-sustainable.html?utm_source=openai)).\n",
       "\n",
       "- **Lightweight 3D Image Modeling**  \n",
       "  The University of Tennessee at Chattanooga unveiled a lightweight AI model optimized for interpretable 3D image modeling with reduced computational demands‚Äîa significant step for efficient visual AI applications ([webpronews.com](https://www.webpronews.com/utcs-lightweight-ai-breakthrough-in-3d-image-modeling/?utm_source=openai)).\n",
       "\n",
       "- **Sustainable Packaging with AI**  \n",
       "  Nestl√© and IBM jointly released a generative AI tool capable of identifying innovative high-barrier packaging materials, highlighting AI‚Äôs growing role in sustainable product development ([nestle.com](https://www.nestle.com/about/research-development/news/ibm-ai-powered-sustainable-packaging?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Adoption Trends, Ethical Considerations & Market Dynamics\n",
       "\n",
       "- **Enterprise Adoption & Scaling Challenges**  \n",
       "  According to the 2025 McKinsey Global Survey, generative and agentic AI are increasingly adopted across organizations. High-performing players are defining clear processes for when human oversight is needed, investing substantial portions (>20%) of their digital budgets in AI, yet most are still working to scale pilot projects into broad deployment ([mckinsey.com](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?utm_source=openai)).\n",
       "\n",
       "- **Rapid Global Adoption**  \n",
       "  A recent report indicates that **78% of organizations now use AI in at least one business function**, up from 55% a year prior‚Äîunderscoring AI's transition from pilot to mainstream utility ([netguru.com](https://www.netguru.com/blog/ai-adoption-statistics?utm_source=openai)).\n",
       "\n",
       "- **Market Fragmentation & Supply Considerations**  \n",
       "  Trade tensions and chip tariffs are driving a geographic shift in AI hardware manufacturing‚Äîmoving supply chains to Vietnam, Mexico, and India. Concurrently, China is reinforcing a self-sufficient AI ecosystem, marking a bifurcation in generative AI infrastructure and development trends ([globenewswire.com](https://www.globenewswire.com/news-release/2025/09/16/3150581/28124/en/Generative-AI-Market-Report-Highlights-US-Tariffs-Rising-Costs-and-Global-AI-Ecosystem-Shifts.html?utm_source=openai)).\n",
       "\n",
       "- **Ethical Adoption in Professional Services**  \n",
       "  At the 2025 Emerging Technology and Generative AI Forum, industry experts emphasized the importance of critical human oversight in ensuring ethical, accountable use of generative AI in professional sectors ([thomsonreuters.com](https://www.thomsonreuters.com/en-us/posts/technology/emerging-technology-generative-ai-forum-ethical-ai-adoption/?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary of the Latest Trends\n",
       "\n",
       "1. **Advanced Multimodal Models**: GPT‚Äë5, Gemini‚ÄØ2.5, Sora‚ÄØ2, and others are pushing the boundaries of reasoning, video, and real-time capabilities.\n",
       "2. **Efficiency & Accessibility**: Smaller, faster models‚Äîlike Claude Haiku 4.5 and open-source Qwen3‚Äîare democratizing powerful AI.\n",
       "3. **Purpose-Built AI Applications**: Tools like SCIGEN, personalized object localization, and optical image generation highlight AI‚Äôs expanding reach.\n",
       "4. **Rapid Organizational Adoption**: Generative AI is becoming mission-critical, though challenges in scaling and oversight remain.\n",
       "5. **Global Ecosystem Dynamics**: Supply-chain reconfigurations and regional AI ecosystems are influencing innovation trajectories.\n",
       "6. **Ethics & Governance**: As generative AI becomes pervasive, ethical deployment and human governance are paramount.\n",
       "\n",
       "---\n",
       "\n",
       "If you‚Äôd like to explore any of these areas further‚Äîbe it technical specifics of a model, enterprise strategy implications, or ethical frameworks‚ÄîI‚Äôd be glad to dive deeper!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a detailed overview of the **latest developments in generative AI** as of November 12, 2025, "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a refreshed and richly detailed overview of **recent developments in generative AI**, drawn from diverse, contemporary sources. This summary spans advances in foundational models, hardware innovations, and industry shifts‚Äîeach with timely citations, and structured for clarity.\n",
       "\n",
       "---\n",
       "\n",
       "## Open-Weight Model Releases & Accessibility\n",
       "\n",
       "- **OpenAI‚Äôs gpt‚Äëoss‚Äë120b and gpt‚Äëoss‚Äë20b**  \n",
       "  In **August 2025**, OpenAI released two open-weight models‚Äîthe first since GPT‚Äë2 in 2019‚Äîdesigned to broaden access to generative AI. The lighter 20B model can run locally on consumer hardware (e.g., 16‚ÄØGB RAM PCs, Snapdragon processors), while the 120B version suits powerful GPUs like NVIDIA RTX and was trained using substantial compute resources. ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai))\n",
       "\n",
       "- **AWS Integration of OpenAI Models**  \n",
       "  In tandem with OpenAI‚Äôs release, **Amazon Web Services (AWS)** began offering these open models on Amazon Bedrock and SageMaker platforms. The 120B model is notably more cost-efficient‚Äîthree times better than Gemini, five times than DeepSeek‚ÄëR1, and twice than OpenAI‚Äôs o4‚Äîempowering millions of developers with flexible, economical generative AI access. ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/amazon-announces-first-ever-availability-of-openai-models-for-its-cloud-customers-company-says-the-addition-of-/articleshow/123125170.cms?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## Multimodal & Reasoning Model Milestones\n",
       "\n",
       "- **OpenAI‚Äôs GPT‚Äë5 (Released August 7, 2025)**  \n",
       "  GPT‚Äë5 delivers integrated reasoning and non-reasoning capabilities as a full-fledged multimodal foundation model. It's available via ChatGPT, Microsoft Copilot, and the OpenAI API, setting new performance benchmarks upon launch. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **Google‚Äôs Gemini Model Enhancements**  \n",
       "  - **Gemini‚ÄØ2.5 Pro and Gemini‚ÄØ2.5 Flash** debuted in mid‚Äë2025, introducing ‚ÄúDeep Think‚Äù reasoning and enhanced multimodal fluency. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai))  \n",
       "  - **Nano Banana** (Gemini‚ÄØ2.5‚ÄØFlash Image) launched publicly on **August‚ÄØ26,‚ÄØ2025**, gaining viral popularity for photorealistic ‚Äú3D figurine‚Äù image generation and driving over 10 million new Gemini app users and 200 million image edits in subsequent weeks. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))  \n",
       "\n",
       "- **Gemini Diffusion**  \n",
       "  An experimental model from DeepMind that uses diffusion techniques to generate text more quickly‚Äîup to **1,479 tokens per second**, compared to ~400 for Gemini‚ÄØ2.5 Flash and ~150 for GPT‚Äë4o‚Äîmarking a breakthrough in the speed of text generation. ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))\n",
       "\n",
       "- **Alibaba‚Äôs Qwen Series**  \n",
       "  - Released **Qwen‚ÄØ2.5‚ÄëVL‚Äë32B‚ÄëInstruct** in March 2025: a multimodal model excelling at reasoning and visual tasks, open-sourced under Apache‚ÄØ2.0. ([sourceforge.net](https://sourceforge.net/articles/breaking-news-biggest-ai-advances-2025-heres-what-you-need-to-know/?utm_source=openai))  \n",
       "  - In **April 2025**, Alibaba launched **Qwen3** family: dense and MoE variants with up to 32B parameters, available via open license and featuring reasoning modes and 128K token context windows. ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))  \n",
       "  - On **September 5, 2025**, **Qwen3‚ÄëMax** was released, surpassing other non‚Äëreasoning models in performance. Its thinking/reasoning capability rolled out publicly in early November 2025. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Qwen?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## Infrastructure: Compute & Hardware Advancements\n",
       "\n",
       "- **NVIDIA‚Äôs Next-Gen AI Chips**  \n",
       "  At **GTC 2025**, NVIDIA revealed its upcoming chip architectures: **Blackwell Ultra** (coming late 2025), **Vera Rubin** (2026 launch), and **Rubin Ultra** (2027). These advances support the growing need for AI and agentic systems. NVIDIA also introduced open-source tools‚Äîincluding the Isaac GR00T N1 robotics model and the Cosmos AI synthetic data model‚Äîand announced the Newton physics engine for robotics simulation. ([apnews.com](https://apnews.com/article/457e9260aa2a34c1bbcc07c98b7a0555?utm_source=openai))\n",
       "\n",
       "- **Qualcomm‚Äôs AI200 and AI250 Accelerators**  \n",
       "  In **October 2025**, Qualcomm announced plans for new data center inference accelerators: **AI200** (2026) and **AI250** (2027). Built on advanced Hexagon NPUs, these systems offer high memory capacity, micro-tile inferencing, Gen AI encryption, and support for AI framework integration‚Äîpositioning Qualcomm as a rising competitor to AMD and NVIDIA in AI infrastructure. ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai))\n",
       "\n",
       "- **AMD‚Äôs MI400 Chips & Helios System**  \n",
       "  Announced in **mid‚Äë2025**, AMD's **Instinct MI400** GPU series and the *Helios* rack-scale architecture (launching 2026) aim to rival NVIDIA‚Äôs solutions by unifying thousands of chips into a cohesive AI compute engine‚Äîendorsed by OpenAI and representing significant competition in the rack-scale AI hardware space. ([linkedin.com](https://www.linkedin.com/pulse/top-5-generative-ai-news-updates-from-week-24-2025-8th-shankar-k2cgc?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## Regional & Organizational Developments\n",
       "\n",
       "- **Tencent‚Äôs Open-Source 3D Generation Tools**  \n",
       "  In **March 2025**, Tencent introduced *Hunyuan3D‚Äë2.0*, releasing five open-source models‚Äîincluding fast ‚Äúturbo‚Äù versions that generate 3D visuals in 30 seconds. This move underscores escalating Chinese capabilities in generative AI, particularly for design and game development. ([reuters.com](https://www.reuters.com/technology/artificial-intelligence/tencent-expands-ai-push-with-open-source-3d-generation-tools-2025-03-18/?utm_source=openai))\n",
       "\n",
       "- **India‚Äôs BharatGen LLM & OpenAI Academy Expansion**  \n",
       "  In **June 2025**, India launched *BharatGen*, a multimodal large language model supporting 22 Indian languages, tailored for localized use in sectors like healthcare and governance. Concurrently, OpenAI revealed its first overseas AI Academy in India, aiming to train developers, educators, and civil servants, backed by substantial computing access and crowdsourced engagement initiatives. ([linkedin.com](https://www.linkedin.com/pulse/top-5-generative-ai-news-updates-from-week-23-2025-1st-shankar-1tj5c?utm_source=openai))\n",
       "\n",
       "- **Hugging Face Enters Robotics**  \n",
       "  Hugging Face unveiled two open-source humanoid robots‚Äî*HopeJR* and *Reachy Mini*‚Äîpriced approximately at US‚ÄØ$3,000 and $250‚Äì300 respectively, expected to ship by end of 2025. These devices are part of the company's mission to democratize robotics innovation and expand beyond software into physical AI. ([linkedin.com](https://www.linkedin.com/pulse/top-5-generative-ai-news-updates-from-week-22-2025-25th-shankar-uahbc?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "### Summary Table (Key Developments)\n",
       "\n",
       "| Category                      | Highlights |\n",
       "|------------------------------|------------|\n",
       "| **Open Models**              | OpenAI‚Äôs gpt‚Äëoss series; AWS integration |\n",
       "| **Model Advances**           | GPT‚Äë5; Gemini 2.5/Flash/Nano Banana; Gemini Diffusion; Alibaba Qwen series |\n",
       "| **Hardware & Compute**       | NVIDIA Rubin chips; Qualcomm AI200/250; AMD MI400 & Helios |\n",
       "| **Regional Innovations**     | Tencent 3D tools; India‚Äôs BharatGen & AI Academy |\n",
       "| **Robotics**                 | Hugging Face‚Äôs HopeJR & Reachy Mini |\n",
       "\n",
       "---\n",
       "\n",
       "If you're interested in any specific area‚Äîwhether it's a deep dive into GPU architectures, licensing strategies, regional AI ecosystems, or the future of robotics‚Äîfeel free to ask. I'm happy to provide more focused analysis!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Recent developments in generative AI include:\n",
       "\n",
       "1. **Market Growth**: The global generative AI market is expected to reach $1.18 billion this year, highlighting its rapid expansion and the increasing importance of adopting these technologies.\n",
       "\n",
       "2. **Enterprise Integration**: IBM's Watsonx is bringing generative AI to enterprises, allowing teams to build custom large language models to enhance customer engagement and streamline processes.\n",
       "\n",
       "3. **Innovation in Content Creation**: Generative AI is being used to create cinematic videos from simple prompts, revolutionizing content creation for marketing and entertainment.\n",
       "\n",
       "4. **Industry Applications**: Generative AI is reshaping various sectors, from supply chain disruption analysis to financial services, by providing innovative solutions and improving efficiency.\n",
       "\n",
       "5. **Ethical and Regulatory Considerations**: There is ongoing discussion about the regulation and ethics of generative AI, focusing on issues like deepfakes and content ownership.\n",
       "\n",
       "These developments indicate a significant shift in how businesses and industries are leveraging AI to innovate and solve complex problems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created: vs_6914e47d5a4481919727f1951253ae44\n",
      "File uploaded: file-PLZkN5U47s5N4SDu7QtoBp\n",
      "File attached to vector store: file-PLZkN5U47s5N4SDu7QtoBp\n",
      "\n",
      "Top retrieved chunks:\n"
     ]
    }
   ],
   "source": [
    "tiy_vector_store = client.vector_stores.create(\n",
    "    name=\"tiy_vector_store\"\n",
    ")\n",
    "tiy_vector_store_id = tiy_vector_store.id\n",
    "print(\"Vector store created:\", tiy_vector_store_id)\n",
    "\n",
    "with open(\"Drone_Interception_Rate.txt\", \"rb\") as f:\n",
    "    uploaded_file = client.files.create(\n",
    "        file=f,\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "print(\"File uploaded:\", uploaded_file.id)\n",
    "\n",
    "\n",
    "attach_result = client.vector_stores.files.create(\n",
    "    vector_store_id=tiy_vector_store_id,\n",
    "    file_id=uploaded_file.id,\n",
    ")\n",
    "print(\"File attached to vector store:\", attach_result.id)\n",
    "\n",
    "\n",
    "test_query = \"Summarize the main ideas from my notes.\"\n",
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=tiy_vector_store_id,\n",
    "    query=test_query,\n",
    ")\n",
    "\n",
    "print(\"\\nTop retrieved chunks:\")\n",
    "for item in search_results.data[:3]:\n",
    "    print(\"-\" * 40)\n",
    "    print(item.content[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### From my file\n",
       "\n",
       "The news article discusses the declining interception rates of Ukrainian air defenses against Russian drones and missiles. In October, the interception rate for drones fell to just under 80%, the lowest of 2025, down from over 90% earlier in the year. Similarly, missile interception rates dropped to 54%, the lowest since April. This decline is attributed to several factors, including an increase in the number of drones launched by Russia, potential shortages in munitions, and possibly adverse weather conditions.\n",
       "\n",
       "The reduced interception rates have significant implications for Ukraine. Russian attacks have increasingly targeted critical infrastructure, particularly energy facilities, leading to widespread blackouts. The Ukrainian government, including President Volodymyr Zelenskyy, has highlighted the inadequacy of the country's air defense systems and the need for more Western support. The cost of intercepting drones with advanced missile systems is high, and Ukraine is struggling to keep up with the growing sophistication and volume of Russian attacks.\n",
       "\n",
       "### From the web\n",
       "\n",
       "I will now look up the latest information on this topic. Please hold on.Here is a structured summary of the topic, clearly separated into two sections:\n",
       "\n",
       "From my file  \n",
       "- The article reports a decline in Ukraine‚Äôs air defense interception rates in 2025. Drone interception fell to just under 80% in October‚Äîthe lowest level of the year‚Äîdown from over 90% earlier. Missile interception dropped to 54%, the lowest since April.  \n",
       "- Contributing factors include a surge in Russian drone launches, possible shortages of interceptors, and adverse weather conditions.  \n",
       "- The decline has had serious consequences: Russian strikes increasingly target critical infrastructure, especially energy facilities, causing widespread blackouts. Ukrainian leaders, including President Zelenskyy, have emphasized the insufficiency of current air defenses and the urgent need for more Western support. The high cost of intercepting drones with advanced missile systems is straining Ukraine‚Äôs resources.  \n",
       "\n",
       "From the web  \n",
       "- In September 2025, Russia‚Äôs upgraded Iskander‚ÄëM and Kinzhal missiles‚Äîwith new terminal-phase maneuvering capabilities‚Äîcaused Ukraine‚Äôs ballistic missile interception rate to plummet from around 37% in August to just 6% in September. This shift has been described as a ‚Äúgame-changer,‚Äù enabling successful strikes on key targets including drone factories and diplomatic offices in Kyiv ([newstarget.com](https://www.newstarget.com/2025-10-06-russia-upgraded-missiles-reduce-ukraine-interception-rate.html?utm_source=openai)).  \n",
       "- As of October 11, 2025, Ukraine‚Äôs overall air defense effectiveness stood at approximately 74%, according to Commander-in-Chief Oleksandr Syrskyi. He noted a 1.3-fold increase in Russian airstrikes over the past month and stressed the need to better protect energy and logistics infrastructure ([kyivindependent.com](https://kyivindependent.com/ukrainian-air-defenses-operating-at-74-effectiveness-syrskyi-says/?utm_source=openai)).  \n",
       "- Ukraine has shifted toward drone-on-drone defense. President Zelenskyy reported a 68% interception rate against Russian Shahed drones using interceptor drones, which cost $3,000‚Äì$5,000 each‚Äîfar less than the $120,000‚Äì$150,000 cost of a Shahed ([united24media.com](https://united24media.com/latest-news/zelenskyy-ukraines-interceptors-achieve-68-success-rate-against-russian-shahed-drones-12417?utm_source=openai)).  \n",
       "- Kyiv has allocated 260 million hryvnias (about $6.2 million) to a drone interceptor program. A pilot phase has already intercepted nearly 550 Russian drones. Plans include establishing a training center and mobile interceptor units ([reuters.com](https://www.reuters.com/business/aerospace-defense/kyiv-allocate-62-million-drone-interceptor-program-2025-07-11/?utm_source=openai)).  \n",
       "- As of early November 2025, Ukraine is ramping up production of interceptor drones, aiming for 600‚Äì800 per day by the end of the month‚Äîthough this falls short of the initial goal of 1,000 per day ([businessinsider.com](https://www.businessinsider.com/ukraine-interceptor-drone-war-800-production-zelenskyy-2025-11?utm_source=openai)).  \n",
       "- The broader air war remains intense: in July 2025, Russia launched a record 728 drones and 13 missiles in a single night. Ukrainian defenses intercepted 296 drones and jammed or lost 415, highlighting the scale of the threat and the strain on Ukraine‚Äôs air defense systems ([apnews.com](https://apnews.com/article/fe3d23673b9b5696bb5097def9ed0775?utm_source=openai)).  \n",
       "- Overall, Ukraine‚Äôs air defense is under severe pressure. In May 2025, interception rates for Shahed drones dropped to around 30%, down from over 90% in 2024, due to improved Russian drone tactics, higher altitudes, heavier payloads, and anti-jamming capabilities ([lemonde.fr](https://www.lemonde.fr/en/international/article/2025/05/26/ukraine-s-air-defense-is-struggling-to-keep-up-with-intensifying-russian-strikes_6741666_4.html?utm_source=openai)).\n",
       "\n",
       "Summary  \n",
       "Ukraine‚Äôs interception rates have declined significantly in 2025, particularly against advanced Russian missiles and drone swarms. The fall in effectiveness has led to increased damage to critical infrastructure and heightened civilian risk. In response, Ukraine is innovating with cost-effective interceptor drones, scaling up production, and investing in new defense programs. However, the evolving nature of Russian attacks continues to challenge Ukraine‚Äôs air defense capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\n",
    "    \"Using the uploaded news article as the primary source, and also checking the latest web information, \"\n",
    "    \"give me a short, structured summary of the topic (This is a abc story about the falling Ukrainian interception rate and its effect on the nation). Clearly separate 'From my file' vs 'From the web'.\"\n",
    ")\n",
    "\n",
    "combined_response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=query,\n",
    "    temperature=0,\n",
    "    instructions=(\n",
    "        \"First look up relevant passages from the attached vector store. \"\n",
    "        \"Then augment with web_search to bring in current/public info. \"\n",
    "        \"Present the answer in two sections: 'From my file(s)' and 'From the web'.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [tiy_vector_store_id],\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(combined_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcce61d-9504-48e6-b65e-5de8b6c61412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
